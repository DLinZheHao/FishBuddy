//
//  ImageRecognitionView.swift
//  FishBuddy
//
//  Created by æ—å“²è±ª on 2025/8/28.
//

import SwiftUI
import AVFoundation
import CoreML

struct CameraStreamView: View {
    /// ç›¸æ©Ÿé¡é ­ç‰©ä»¶
    @StateObject private var camera = CameraController()
    /// ViewModel
    @ObservedObject private var vm = CameraStreamVM()
    /// æœ€å¾Œä¸€æ¬¡æ‹æ”ç…§ç‰‡
    @State private var lastPhoto: UIImage?
    /// æ¸¬è©¦åˆ‡å‰²å¾Œçš„ç…§ç‰‡çµæœ
    @State private var resultImage: UIImage?
    /// æ‹æ”é‹ä½œæ¨¡å¼
    typealias CaptureMode = CameraStreamVM.CaptureMode
    
    var body: some View {
        ZStack {
            // Full-screen camera preview (edge-to-edge)
            ZStack {
                CameraPreview(session: vm.captureSession)
                    .frame(maxWidth: .infinity, maxHeight: .infinity)
                    .ignoresSafeArea()

                if camera.captureSession == nil {
                    // é¦–æ¬¡å•Ÿå‹•å°šæœªæœ‰ session æ™‚é¡¯ç¤º loading
                    ProgressView("å•Ÿå‹•ç›¸æ©Ÿä¸­â€¦")
                        .padding()
                        .background(.ultraThinMaterial, in: RoundedRectangle(cornerRadius: 12))
                }
            }
            // ç•¶æ›æˆã€Œæ–°çš„ã€AVCaptureSession å¯¦ä¾‹æ™‚ï¼Œå¼·åˆ¶ SwiftUI é‡æ–°å»ºæ§‹é è¦½ï¼ˆæ¯æ¬¡åˆ‡æ›éƒ½æœƒé–‹å•Ÿæ–°çš„ sessionï¼‰
            .id(camera.captureSession.map { ObjectIdentifier($0) }) // ObjectIdentifier æ˜¯ä¸€ç¨®ã€Œä»¥ç‰©ä»¶è¨˜æ†¶é«”èº«ä»½ä½œç‚ºå”¯ä¸€å€¼ã€çš„æ±è¥¿

            // Overlay UI
            VStack {
                HStack {
                    Spacer()
                    // åˆ‡æ›å‰/å¾Œé¡é ­
                    Toggle("å¾Œé¡é ­", isOn: Binding(
                        get: { camera.backCamera },
                        set: { camera.backCamera = $0 }
                    ))
                    .labelsHidden()
                    .padding(10)
                    .background(.ultraThinMaterial, in: Capsule())
                }
                .padding(.top, 12)
                .padding(.horizontal, 16)

                Spacer()

                // æœå°‹çµæœé¡¯ç¤ºï¼ˆä¸Šæ–¹å·¦å´æµ®å‡ºï¼‰
                if let results = vm.imageSearchResult, !results.isEmpty {
                    VStack(alignment: .leading, spacing: 8) {
                        Text("ğŸ“· æœå°‹çµæœ")
                            .font(.headline)
                            .padding(.bottom, 4)

                        ForEach(Array(results.prefix(3)), id: \.0.taxonId) { (item, score) in
                            HStack {
                                RoundedRectangle(cornerRadius: 6)
                                    .fill(.blue.opacity(0.1))
                                    .frame(width: 40, height: 40)
                                    .overlay(
                                        Text(String(item.taxonId))
                                            .font(.caption)
                                            .foregroundStyle(.blue)
                                    )

                                VStack(alignment: .leading) {
                                    Text("ID: \(item.taxonId)")
                                        .font(.subheadline)
                                        .foregroundColor(.primary)
                                    Text(String(format: "ç›¸ä¼¼åº¦: %.2f", score))
                                        .font(.caption)
                                        .foregroundColor(.secondary)
                                }

                                Spacer()
                            }
                            .padding(.vertical, 4)
                            .padding(.horizontal, 8)
                            .background(RoundedRectangle(cornerRadius: 8).fill(.secondary.opacity(0.1)))
                        }
                    }
                    .padding(12)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .background(.ultraThinMaterial, in: RoundedRectangle(cornerRadius: 12))
                    .padding(.horizontal, 16)
                }
                
                if let resultImage {
                    Image(uiImage: resultImage)
                        .resizable()
                        .scaledToFit()
                        .frame(maxHeight: 200)
                        .clipShape(RoundedRectangle(cornerRadius: 12))
                        .padding()
                }
            }
            
            
        }
        // åœ¨ safeArea æ’°å¯«å·¥å…·
        .safeAreaInset(edge: .bottom) {
            HStack(spacing: 16) {
                if let _ = lastPhoto {
                    Color.clear
                        .frame(width: 56, height: 56)
                }
                Spacer()

                Button {
                    camera.capturePhoto()
                } label: {
                    Label("æ‹ç…§", systemImage: "camera.circle")
                        .font(.title2)
                }
                .buttonStyle(.borderedProminent)

                Spacer(minLength: 0)

                if let image = lastPhoto {
                    Image(uiImage: image)
                        .resizable()
                        .scaledToFill()
                        .frame(width: 56, height: 56)
                        .clipShape(RoundedRectangle(cornerRadius: 8))
                        .overlay(RoundedRectangle(cornerRadius: 8).stroke(.secondary.opacity(0.4), lineWidth: 1))
                        .accessibilityLabel("æœ€æ–°æ‹æ”ç¸®åœ–")
                }
            }
            .padding(.horizontal, 16)
            .padding(.vertical, 12)
            .background(.ultraThinMaterial)
        }
        .onAppear {
            // è®€å– database
            vm.loadDatabaseIfNeeded()

            // æ¯æ¬¡å›åˆ°æ­¤é éƒ½é‡æ–°å»ºç«‹ä¸€æ¢æ–°çš„ embeddings streamï¼Œ
            // è®“æ¶ˆè²»ç«¯çš„ for-await èƒ½å¯é é‡å•Ÿï¼›Camera æœ¬èº«ä¸æœƒé‡é–‹ã€‚
            let stream = AsyncStream<[Float32]> { continuation in
                camera.attachEmbedding(continuation: continuation)
                // åƒ…åœ¨å°šæœªå•Ÿå‹•æ™‚æ‰æœƒçœŸæ­£å•Ÿå‹•ç›¸æ©Ÿ
                camera.startIfNeeded()
            }
            vm.embeddings = stream
            vm.streamID = UUID()

            // åªåœ¨ç¬¬ä¸€æ¬¡è¼‰å…¥æ™‚å»ºç«‹èˆ‡é ç†± CLIP æ¨¡å‹ã€ visionKit ä¹Ÿåœ¨é€™è£¡é è¼‰
            if !vm.didLoadExtractor {
                Task.detached(priority: .userInitiated) {
                    let remover = await BackgroundRemoverVK()
                    let extractor = CLIPFeatureExtractor()
                    // é ç†±ï¼šè®“ç¬¬ä¸€æ¬¡æ¨è«–ä¸å¡
                    let renderer = UIGraphicsImageRenderer(size: CGSize(width: 224, height: 224))
                    let warmup = renderer.image { _ in
                        UIColor.black.setFill()
                        UIBezierPath(rect: CGRect(x: 0, y: 0, width: 224, height: 224)).fill()
                    }
                    _ = extractor.embedding(for: warmup)
                    await MainActor.run {
                        camera.backgroundRemoverVK = remover
                        camera.clipExtractor = extractor
                        vm.didLoadExtractor = true
                    }
                }
            }

            camera.onSessionReady = { session in
                DispatchQueue.main.async {
                    self.vm.captureSession = session
                }
            }
            camera.onPhotoReady = { data in
                self.lastPhoto = data.1
                Task {
                    await self.vm.search(query: data.0)
                }
            }
            
            camera.backgroundRemove = { image in
                self.resultImage = image
            }
        }
        .onDisappear {
            // åœ¨ Tab åˆ‡æ›æ™‚ä¸è¦åœæ­¢ç›¸æ©Ÿèˆ‡é‡‹æ”¾è³‡æºï¼Œé¿å…é‡å»ºæˆæœ¬
            // è‹¥éœ€è¦åœ¨çœŸæ­£é›¢é–‹åŠŸèƒ½é æ™‚é‡‹æ”¾ï¼Œè«‹åœ¨ä¸Šå±¤åšé›†ä¸­ç®¡ç†å†å‘¼å« stop/detatchã€‚
        }
    }
}

// MARK: - UIKit bridge for live camera preview (best for low-latency display)
final class PreviewView: UIView {
    override class var layerClass: AnyClass { AVCaptureVideoPreviewLayer.self }
    var videoPreviewLayer: AVCaptureVideoPreviewLayer { layer as! AVCaptureVideoPreviewLayer }
}

struct CameraPreview: UIViewRepresentable {
    let session: AVCaptureSession?

    func makeUIView(context: Context) -> PreviewView {
        let v = PreviewView(frame: .zero)
        v.videoPreviewLayer.videoGravity = .resizeAspectFill
        return v
    }

    func updateUIView(_ uiView: PreviewView, context: Context) {
        // è‹¥å¾Œä¾†æ‰å–å¾— sessionï¼Œæˆ–æ›äº†æ–°çš„ sessionï¼Œéƒ½åœ¨æ­¤æ›´æ–°
        if uiView.videoPreviewLayer.session !== session {
            uiView.videoPreviewLayer.session = session
        }
    }
}

// åƒ…å‚³é [Float]ï¼Œé¿å… CMSampleBuffer çš„ Sendable å•é¡Œ
struct EmbeddingConsumer: View {
    let stream: AsyncStream<[Float32]>
    let id: UUID

    var body: some View {
        Text("æ”å½±æ©Ÿå·²å•Ÿå‹•")
            .task(id: id) {
                var idx = 0
                for await vec in stream {
                    idx += 1
//                    print("[UI] got embedding #\(idx), dim=\(vec.count)")
                }
            }
    }
}
